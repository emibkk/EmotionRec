########### Import Modules ##############
import pathlib
import numpy as np
import matplotlib.pyplot as plt
import skimage.io
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras.preprocessing import image_dataset_from_directory
from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout, BatchNormalization, Activation, Conv2D, MaxPooling2D
from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping
from tensorflow.python.keras import regularizers
from tensorflow.keras.utils import plot_model
from sklearn.metrics import accuracy_score
import os
os.environ["PATH"] += os.pathsep + 'C:/Program Files/Graphviz/bin/'
####### Importing and analyzing dataset ##########


path_test= 'C:/data/test'
path_train= 'C:/data/train'
data_dir_test =pathlib.Path(path_test)
data_dir_train =pathlib.Path(path_train)
image_count_test = len(list(data_dir_test.glob('*/*.jpg')))
image_count_train = len(list(data_dir_train.glob('*/*.jpg')))
print("Image count test folder: ", image_count_test)
print("Image count train folder: ", image_count_train)

# load an example image
im = load_img('C:/data/train/angry/Training_33331.jpg')

# summarize some details about the image
print("Image format: ", im.format)
print("Image mode: ", im.mode)
print("Image size: ", im.size)

# Datagen to manipulate the image data after it is loaded, including pixel scaling and data augmentation.
#Followed from source: https://machinelearningmastery.com/how-to-configure-image-data-augmentation-when-training-deep-learning-neural-networks/
train_datagen = ImageDataGenerator(rescale=1. / 255,
                                   validation_split=0.2,
                                   #rotation_range=5,
                                   #width_shift_range=0.2,
                                   #height_shift_range=0.2,
                                   #shear_range=0.2,
                                   horizontal_flip=True,
                                   #vertical_flip=True,
                                   #zoom_range=0.3,
                                   fill_mode='nearest')

test_datagen = ImageDataGenerator(rescale=1. / 255
                                  )

train_dataset = train_datagen.flow_from_directory(directory = 'C:/data/train',
                                                  target_size = (48,48),
                                                  class_mode = 'categorical',
                                                  #subset = 'training',
                                                  shuffle=True,
                                                  color_mode='grayscale',
                                                  batch_size = 64)

test_dataset = test_datagen.flow_from_directory(directory = 'C:/data/test',
                                                target_size = (48,48),
                                                class_mode = 'categorical',
                                                shuffle=True,
                                                color_mode='grayscale',
                                                batch_size = 16)


print(train_dataset.class_indices)

######################### Define Model ###########################
#Define metrics
METRICS = [
    tf.keras.metrics.BinaryAccuracy(name='accuracy'),
    tf.keras.metrics.Precision(name='precision'),
    tf.keras.metrics.Recall(name='recall'),
    tf.keras.metrics.AUC(name='auc'),
    tfa.metrics.F1Score(num_classes=7, name='f1_score', average='macro'),
]

# Initialising the CNN
model = Sequential()

model.add(Conv2D(32, kernel_size=(3, 3), padding='same', activation='relu', input_shape=(48, 48, 1)))
model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D(2, 2))
model.add(Dropout(0.25))

model.add(Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same', kernel_regularizer=regularizers.l2(0.01)))
model.add(Conv2D(256, kernel_size=(3, 3), activation='relu', kernel_regularizer=regularizers.l2(0.01)))
model.add(BatchNormalization())
model.add(MaxPooling2D(pool_size=(2, 2)))
model.add(Dropout(0.25))

model.add(Flatten())
model.add(Dense(1024, activation='relu'))
model.add(Dropout(0.5))

model.add(Dense(7, activation='softmax'))

# Compiling model
model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=METRICS)

# Display the model's architecture and summarize model
model.summary()
#plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True) #not working



############ Callbacks function ############
lrd = ReduceLROnPlateau(monitor='val_loss', patience=20, verbose=1, factor=0.50, min_lr=1e-10)

mcp = ModelCheckpoint('model.h5')

es = EarlyStopping(verbose=1, patience=20)


# Fit the model

history = model.fit(train_dataset,
                 validation_data=test_dataset,
                 epochs=10,
                 callbacks=[lrd, mcp, es],
                 steps_per_epoch=len(train_dataset),
                 #batch_size=10, verbose=1,
                 validation_steps=len(test_dataset))


# evaluate model
#score = model.evaluate(test_dataset, test_dataset.class_indices, verbose=0) #not working, what needs to be changed?
#print(f'Test loss: {score[0]} / Test accuracy: {score[1]}')

#############3 Loss and Accuracy Plot ################
plt.figure(figsize=(14,5))
plt.subplot(1,5,1)
plt.plot(history.history['accuracy'])
plt.plot(history.history['val_accuracy'])
plt.title('Model Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend(['train', 'test'], loc='upper left')

plt.subplot(1,5,2)
plt.plot(history.history['loss'])
plt.plot(history.history['val_loss'])
plt.title('model Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend(['train', 'test'], loc='upper left')

plt.subplot(1,5,3)
plt.plot(history.history['precision'])
plt.plot(history.history['val_precision'])
plt.title('Model precision')
plt.ylabel('Precision')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

plt.subplot(1,5,4)
plt.plot(history.history['recall'])
plt.plot(history.history['val_recall'])
plt.title('Model recall')
plt.ylabel('Recall')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')

plt.subplot(1,5,5)
plt.plot(history.history['f1_score'])
plt.plot(history.history['val_f1_score'])
plt.title('Model F1 score')
plt.ylabel('F1 score')
plt.xlabel('Epoch')
plt.legend(['Train', 'Test'], loc='upper left')
plt.show()

########## Confusion Matrix ######
from sklearn.metrics import classification_report, confusion_matrix
y_pred = model.predict(train_dataset)
y_pred = np.argmax(y_pred, axis=1)
class_labels = test_dataset.class_indices
class_labels = {v:k for k,v in class_labels.items()}

cm_test = confusion_matrix(train_dataset.classes, y_pred)
print('Confusion Matrix')
print(cm_test)
print('Classification Report')
target_names = list(class_labels.values())
print(classification_report(train_dataset.classes, y_pred, target_names=target_names))
print('PERFORMANCE of model on test set:  %f' % (accuracy_score(train_dataset.classes,y_pred)))
print("Accuracy = ", accuracy_score(train_dataset.classes, y_pred))

plt.figure(figsize=(8,8))
plt.imshow(cm_test, interpolation='nearest')
plt.colorbar()
tick_mark = np.arange(len(target_names))
_ = plt.xticks(tick_mark, target_names, rotation=90)
_ = plt.yticks(tick_mark, target_names)

